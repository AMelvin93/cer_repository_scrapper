---
phase: 06-deep-analysis-features
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - config/prompts/filing_analysis.txt
  - src/cer_scraper/analyzer/service.py
autonomous: true

must_haves:
  truths:
    - "The enriched prompt instructs Claude to produce regulatory implications (or null for routine filings)"
    - "The enriched prompt instructs Claude to extract ALL dates with temporal status relative to analysis_date"
    - "The enriched prompt instructs Claude to assess sentiment with both fixed category and free-form nuance"
    - "The enriched prompt instructs Claude to select 1-5 representative quotes with optional source location"
    - "The enriched prompt instructs Claude to rate impact 1-5 with justification"
    - "The prompt template uses {analysis_date} placeholder correctly"
    - "All literal braces in the template are doubled ({{ }}) to avoid .format() KeyError"
    - "service.py passes analysis_date=datetime.date.today().isoformat() to build_prompt"
    - "The enriched prompt template formats without error when all placeholders are provided"
  artifacts:
    - path: "config/prompts/filing_analysis.txt"
      provides: "Enriched prompt template with Phase 5 + Phase 6 analysis instructions"
      contains: "regulatory_implications"
    - path: "src/cer_scraper/analyzer/service.py"
      provides: "Updated analyze_filing_text passing analysis_date to build_prompt"
      contains: "analysis_date"
  key_links:
    - from: "config/prompts/filing_analysis.txt"
      to: "src/cer_scraper/analyzer/prompt.py"
      via: "Template placeholders must match build_prompt format args"
      pattern: "\\{analysis_date\\}"
    - from: "src/cer_scraper/analyzer/service.py"
      to: "src/cer_scraper/analyzer/prompt.py"
      via: "analyze_filing_text calls build_prompt with analysis_date kwarg"
      pattern: "analysis_date="
    - from: "config/prompts/filing_analysis.txt"
      to: "src/cer_scraper/analyzer/schemas.py"
      via: "Prompt JSON schema description field names must match AnalysisOutput schema"
      pattern: "regulatory_implications.*sentiment.*impact"
---

<objective>
Replace the Phase 5 prompt template with an enriched version covering all five deep analysis dimensions, and wire service.py to pass the analysis_date parameter.

Purpose: Complete the Phase 6 integration so that the next Claude CLI invocation produces the full 10-field analysis output. This is the final plan -- after this, the analysis pipeline produces deep analysis for every filing.

Output: Enriched filing_analysis.txt prompt template and updated service.py call site.
</objective>

<execution_context>
@C:\Users\amelv\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\amelv\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-deep-analysis-features/06-CONTEXT.md
@.planning/phases/06-deep-analysis-features/06-RESEARCH.md
@.planning/phases/06-deep-analysis-features/06-01-SUMMARY.md
@config/prompts/filing_analysis.txt
@src/cer_scraper/analyzer/service.py
@src/cer_scraper/analyzer/prompt.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace filing_analysis.txt with enriched prompt template</name>
  <files>config/prompts/filing_analysis.txt</files>
  <action>
Replace the entire content of filing_analysis.txt with the enriched prompt template that covers both Phase 5 and Phase 6 analysis dimensions. The template must:

**Retain all existing Phase 5 content:**
- System role instruction (expert regulatory analyst)
- "Return ONLY a valid JSON object" instruction
- {json_schema_description} placeholder
- Classification taxonomy (10 CER document types)
- Entity types and roles reference
- Phase 5 field instructions (summary, entities, relationships, classification, key_facts)
- Edge cases section (missing metadata, French language, short text, multi-document)
- Filing metadata block with all existing placeholders
- Document text section with {document_text}

**Add Phase 6 deep analysis instructions** between the Phase 5 instructions and the edge cases section. Structure the instructions clearly with a "DEEP ANALYSIS" header. For each dimension, implement the user's locked decisions exactly:

**regulatory_implications (per user decision):**
- Brief summary: 2-3 sentences covering the main regulatory impact
- Affected parties: name specific companies/communities/stakeholders when mentioned, fall back to general categories otherwise
- NO recommended next steps or action items -- just describe what the filing means
- Set to null for routine administrative filings (procedural notices, standard compliance acknowledgments)
- Be explicit about when to use null: "If this is a routine administrative filing with no meaningful regulatory implications (e.g., procedural notices, standard compliance acknowledgments, routine correspondence), set regulatory_implications to null. For ALL other filings, provide the implications object."

**dates (per user decision):**
- Extract ALL dates found in the filing with their context
- Today's date is {analysis_date} -- use for computing temporal_status
- temporal_status: "past" if before today, "upcoming" if after today, "today" if matches today
- ISO 8601 (YYYY-MM-DD) when possible; descriptive text for vague/relative dates ("Q1 2026", "within 30 days")
- Always return the dates array -- empty array [] if no dates found

**sentiment (per user decision):**
- Dual output: fixed category (routine, notable, urgent, adversarial, cooperative) PLUS free-form nuance
- Category must be exactly one of the five options
- Nuance is a brief description (e.g. "cautiously supportive with procedural concerns")

**quotes (per user decision):**
- Purpose: quick scanning -- let the reader decide if they need to read the full filing
- 1-2 sentences per quote, short and punchy
- 1-5 quotes proportional to filing length and number of notable passages
- Tag with source_location (document name, page/section) when identifiable, null otherwise

**impact (per user decision):**
- Score 1-5 based on reader urgency:
  1 = Informational only, no action needed
  2 = Minor update, worth noting
  3 = Moderate significance, review recommended
  4 = High significance, timely review important
  5 = Critical, requires immediate attention
- 1-2 sentence justification explaining the score
- Same analysis depth for ALL filings regardless of score

**Add {analysis_date} to the filing metadata block:**
```
- Analysis Date: {analysis_date}
```

**CRITICAL -- Double-brace all literal JSON in the template:**
Every `{` and `}` that is NOT a Python .format() placeholder must be doubled to `{{` and `}}`. This is a known Phase 5 pitfall (see MEMORY.md). The template uses Python str.format() for variable substitution. The only single-brace items should be the placeholders: {json_schema_description}, {filing_id}, {filing_date}, {applicant}, {filing_type}, {num_documents}, {num_missing}, {analysis_date}, {document_text}.

Specifically watch for the example in the relationships instruction -- the existing template already has `{{"subject": "TC Energy", ...}}` with doubled braces. Maintain this pattern for any new JSON examples added for Phase 6 fields.
  </action>
  <verify>
Run: `cd C:\Users\amelv\Repo\cer_repository_scrapper && uv run python -c "
from pathlib import Path
template = Path('config/prompts/filing_analysis.txt').read_text(encoding='utf-8')

# Check all Phase 6 keywords present
for keyword in ['regulatory_implications', 'temporal_status', 'sentiment', 'quotes', 'impact', 'analysis_date', 'affected_parties', 'source_location']:
    assert keyword in template, f'Missing: {keyword}'
print('All Phase 6 keywords present in template')

# Check all required placeholders present
for ph in ['json_schema_description', 'filing_id', 'filing_date', 'applicant', 'filing_type', 'num_documents', 'num_missing', 'analysis_date', 'document_text']:
    assert '{' + ph + '}' in template, f'Missing placeholder: {ph}'
print('All placeholders present')

# Test .format() does not raise KeyError
from cer_scraper.analyzer.prompt import get_json_schema_description
result = template.format(
    json_schema_description=get_json_schema_description(),
    filing_id='C12345',
    filing_date='2026-02-16',
    applicant='TC Energy',
    filing_type='Application',
    num_documents=2,
    num_missing=0,
    analysis_date='2026-02-16',
    document_text='Sample filing text here.',
)
assert 'C12345' in result
assert '2026-02-16' in result
assert 'regulatory_implications' in result
print('Template .format() succeeds without KeyError')
print(f'Formatted prompt length: {len(result)} chars')
"`
  </verify>
  <done>filing_analysis.txt contains the complete enriched prompt with all Phase 5 + Phase 6 instructions. Template formats without KeyError. All 9 placeholders present. Locked decisions for each dimension implemented exactly as specified in CONTEXT.md.</done>
</task>

<task type="auto">
  <name>Task 2: Wire service.py to pass analysis_date to build_prompt</name>
  <files>src/cer_scraper/analyzer/service.py</files>
  <action>
Make a single change in the analyze_filing_text function in service.py.

In the "Build the prompt" section, after the existing `json_schema_description = get_json_schema_description()` line, add:

```python
analysis_date = datetime.date.today().isoformat()
```

Note: `datetime` is already imported in service.py (`import datetime` is on line 11).

Then update the `build_prompt()` call to include the new parameter:

```python
prompt = build_prompt(
    template=template,
    filing_id=filing_id,
    filing_date=filing_date,
    applicant=applicant,
    filing_type=filing_type,
    document_text=document_text,
    num_documents=num_documents,
    num_missing=num_missing,
    json_schema_description=json_schema_description,
    analysis_date=analysis_date,
)
```

This is a minimal, surgical change. Do NOT modify any other part of service.py -- the _invoke_claude_cli function, strip_code_fences, error handling, and all other paths remain unchanged.
  </action>
  <verify>
Run: `cd C:\Users\amelv\Repo\cer_repository_scrapper && uv run python -c "
import ast, inspect
from cer_scraper.analyzer import service

# Verify service module loads without error
print('service.py imports successfully')

# Check analyze_filing_text source contains analysis_date
src = inspect.getsource(service.analyze_filing_text)
assert 'analysis_date' in src, 'analysis_date not found in analyze_filing_text'
assert 'datetime.date.today()' in src, 'datetime.date.today() call not found'
print('analyze_filing_text contains analysis_date wiring')

# Verify build_prompt is called with analysis_date
assert 'analysis_date=analysis_date' in src, 'analysis_date not passed to build_prompt'
print('build_prompt called with analysis_date=analysis_date')
"`
  </verify>
  <done>service.py computes analysis_date from datetime.date.today().isoformat() and passes it to build_prompt(). No other changes to service.py. The analysis pipeline will now produce enriched output on next invocation.</done>
</task>

</tasks>

<verification>
1. Full integration test -- the entire prompt builds without error:
   ```
   uv run python -c "
   from cer_scraper.analyzer.prompt import load_prompt_template, get_json_schema_description, build_prompt
   from cer_scraper.config.settings import PROJECT_ROOT
   from pathlib import Path
   import datetime

   template, version = load_prompt_template(PROJECT_ROOT / 'config/prompts/filing_analysis.txt')
   schema_desc = get_json_schema_description()
   analysis_date = datetime.date.today().isoformat()

   prompt = build_prompt(
       template=template,
       filing_id='C99999',
       filing_date='2026-02-16',
       applicant='Test Corp',
       filing_type='Application',
       document_text='--- Document 1: test.pdf (5 pages) ---\n\nSample filing text.',
       num_documents=1,
       num_missing=0,
       json_schema_description=schema_desc,
       analysis_date=analysis_date,
   )
   assert 'C99999' in prompt
   assert 'regulatory_implications' in prompt
   assert analysis_date in prompt
   print(f'Integration test passed. Prompt version: {version}, length: {len(prompt)} chars')
   "
   ```
2. Schema backward compatibility: Phase 5 JSON (5 fields) validates against extended AnalysisOutput
3. Schema forward compatibility: Full Phase 6 JSON (10 fields) validates against extended AnalysisOutput
4. No import errors across the entire analyzer module
</verification>

<success_criteria>
- filing_analysis.txt contains enriched prompt with all 5 deep analysis dimensions
- Template uses {analysis_date} placeholder and all literal braces are doubled
- service.py passes analysis_date=datetime.date.today().isoformat() to build_prompt
- Full integration: load template -> build prompt -> format succeeds without error
- Prompt includes explicit instructions for null regulatory_implications on routine filings
- Prompt includes the 1-5 impact score rubric with descriptions for each level
- Prompt instructs 1-5 quotes proportional to filing length
</success_criteria>

<output>
After completion, create `.planning/phases/06-deep-analysis-features/06-02-SUMMARY.md`
</output>
