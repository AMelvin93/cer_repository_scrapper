---
phase: 04-pdf-text-extraction
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/cer_scraper/extractor/pymupdf_extractor.py
  - src/cer_scraper/extractor/pdfplumber_extractor.py
  - src/cer_scraper/extractor/quality.py
  - src/cer_scraper/extractor/service.py
autonomous: true

must_haves:
  truths:
    - "pymupdf4llm extracts machine-generated PDFs to markdown with headings, tables, and page separators"
    - "pdfplumber extracts table-heavy PDFs to markdown with pipe-delimited tables when pymupdf4llm quality check fails"
    - "Tesseract OCR extracts scanned/image PDFs via PyMuPDF pixmap rendering as a last resort"
    - "Quality checks detect garbled output (insufficient chars, high garble ratio, excessive repetition) and trigger fallback"
    - "Encrypted PDFs are detected and return extraction_failed with reason 'encrypted'"
    - "PDFs exceeding max_pages_for_extraction are skipped with reason 'too_many_pages'"
    - "A 50-page PDF producing fewer than 100 characters triggers fallback (per user requirement)"
  artifacts:
    - path: "src/cer_scraper/extractor/pymupdf_extractor.py"
      provides: "Primary pymupdf4llm extraction"
      exports: ["try_pymupdf4llm"]
      min_lines: 30
    - path: "src/cer_scraper/extractor/pdfplumber_extractor.py"
      provides: "pdfplumber table-focused fallback extraction"
      exports: ["try_pdfplumber"]
      min_lines: 40
    - path: "src/cer_scraper/extractor/quality.py"
      provides: "Garble detection and quality validation"
      exports: ["passes_quality_check"]
      min_lines: 30
    - path: "src/cer_scraper/extractor/service.py"
      provides: "Per-document tiered extraction orchestration"
      exports: ["extract_document", "ExtractionResult", "ExtractionMethod"]
      min_lines: 50
  key_links:
    - from: "src/cer_scraper/extractor/service.py"
      to: "src/cer_scraper/extractor/pymupdf_extractor.py"
      via: "try_pymupdf4llm function call"
      pattern: "try_pymupdf4llm"
    - from: "src/cer_scraper/extractor/service.py"
      to: "src/cer_scraper/extractor/pdfplumber_extractor.py"
      via: "try_pdfplumber function call"
      pattern: "try_pdfplumber"
    - from: "src/cer_scraper/extractor/service.py"
      to: "src/cer_scraper/extractor/quality.py"
      via: "passes_quality_check function call"
      pattern: "passes_quality_check"
    - from: "src/cer_scraper/extractor/service.py"
      to: "src/cer_scraper/config/settings.py"
      via: "ExtractionSettings parameter"
      pattern: "ExtractionSettings"
---

<objective>
Implement the three-tier PDF extraction pipeline: pymupdf4llm primary extractor, pdfplumber table-focused fallback, direct Tesseract last resort, plus quality validation that triggers fallback when garbled output is detected.

Purpose: This is the core extraction logic. Each extractor converts a PDF to markdown. The service orchestrates the tiered fallback: try pymupdf4llm, check quality, fall back to pdfplumber, check quality, fall back to Tesseract. Handles edge cases: encrypted PDFs, oversized documents, completely unreadable files.

Output: Four new files in the extractor package -- the per-document extraction service, two extractor implementations, and quality checking logic.
</objective>

<execution_context>
@C:\Users\amelv\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\amelv\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-pdf-text-extraction/04-CONTEXT.md
@.planning/phases/04-pdf-text-extraction/04-RESEARCH.md
@.planning/phases/04-pdf-text-extraction/04-01-SUMMARY.md
@src/cer_scraper/config/settings.py
@src/cer_scraper/db/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extraction engines and quality checker</name>
  <files>src/cer_scraper/extractor/pymupdf_extractor.py, src/cer_scraper/extractor/pdfplumber_extractor.py, src/cer_scraper/extractor/quality.py</files>
  <action>
**File 1: `src/cer_scraper/extractor/pymupdf_extractor.py`**

Create the primary extraction function `try_pymupdf4llm(pdf_path: Path, settings: ExtractionSettings) -> ExtractionResult`.

CRITICAL import order: `import pymupdf.layout` MUST come BEFORE `import pymupdf4llm` to activate layout-aware extraction mode. Use a `# noqa: F401` comment on the layout import since it's a side-effect import.

Implementation:
- Call `pymupdf4llm.to_markdown()` with these parameters:
  - `str(pdf_path)` (must be string, not Path)
  - `pages=None` (all pages)
  - `use_ocr=True` (auto-detect and OCR scanned pages)
  - `ocr_language=settings.ocr_language` (default "eng")
  - `table_strategy=settings.table_strategy` (default "lines_strict")
  - `page_chunks=False` (single string output)
  - `show_progress=False`
  - `embed_images=False`
  - `write_images=False`
  - `force_text=True` (extract text from image-overlapping areas)
- Count meaningful characters by stripping markdown syntax and whitespace: `re.sub(r'[#|*_\-\s\n]', '', md_text)`
- Get page count from the PDF (open with pymupdf, get len(doc), close)
- Return `ExtractionResult` with success=True, the markdown text, method=PYMUPDF4LLM, char_count, page_count
- Wrap in try/except, return ExtractionResult(success=False, error=str(e)) on any exception
- Log warnings on failure

**File 2: `src/cer_scraper/extractor/pdfplumber_extractor.py`**

Create fallback function `try_pdfplumber(pdf_path: Path, settings: ExtractionSettings) -> ExtractionResult`.

Implementation (follows research Pattern 3):
- Open PDF with `pdfplumber.open(str(pdf_path))`
- For each page:
  - Find tables with `page.find_tables()`
  - If tables found:
    - Clamp each table bbox to page boundaries to avoid ValueError (see pitfall 5 in research)
    - Filter non-table text using `page.filter()` with `get_bbox_overlap` / `obj_to_bbox` from `pdfplumber.utils`
    - Extract filtered text with `filtered_page.extract_text(layout=True)`
    - Convert each table to markdown via `pd.DataFrame(table_data[1:], columns=table_data[0]).to_markdown(index=False)`
    - Combine text + tables for the page
  - If no tables: extract text with `page.extract_text(layout=True)`
  - Join pages with `\n\n---\n\n` separators (page breaks per user decision)
- Count meaningful characters same way as pymupdf extractor
- Get page count from number of pages iterated
- Return ExtractionResult with method=PDFPLUMBER
- Handle edge cases: empty pages, tables with no rows, None table data
- Wrap in try/except

**File 3: `src/cer_scraper/extractor/quality.py`**

Create quality validation functions:

1. `passes_quality_check(result: ExtractionResult, page_count: int, settings: ExtractionSettings) -> bool`
   - Check 1 (minimum content): `result.char_count < max(100, page_count * settings.min_chars_per_page)` -> fail. This implements the user's explicit requirement: "50-page PDF with <100 chars triggers warning and fallback".
   - Check 2 (garble ratio): count `[\ufffd\x00-\x08\x0b\x0c\x0e-\x1f]` chars, fail if ratio > `settings.garble_ratio_threshold` (0.05)
   - Check 3 (excessive repetition): in first 10K chars, check if any 3-char sequence repeats > 50 times -> fail (font mapping issue)
   - Log warnings with specific failure reason on each check
   - Return True if all checks pass

2. `passes_ocr_quality_check(result: ExtractionResult, page_count: int, settings: ExtractionSettings) -> bool`
   - Looser thresholds for OCR output:
   - Min chars: `max(50, page_count * settings.min_chars_per_page_ocr)` (20 chars/page)
   - Garble ratio: `settings.ocr_garble_ratio_threshold` (0.10)
   - Skip repetition check (OCR doesn't produce font-mapping repetition)
   - Return True if checks pass

Both functions must return False for empty/whitespace-only markdown.

Import `ExtractionResult` from a shared types location. Since service.py defines ExtractionResult but hasn't been created yet, define ExtractionResult and ExtractionMethod in service.py (Task 2 below) and import from there. If circular import is a concern, define the dataclass/enum in a separate `types.py` -- but try service.py first since quality.py is only imported BY service.py (no circular dependency).
  </action>
  <verify>
Run `uv run python -c "from cer_scraper.extractor.pymupdf_extractor import try_pymupdf4llm; print('pymupdf extractor OK')"` to verify import.

Run `uv run python -c "from cer_scraper.extractor.pdfplumber_extractor import try_pdfplumber; print('pdfplumber extractor OK')"` to verify import.

Run `uv run python -c "from cer_scraper.extractor.quality import passes_quality_check, passes_ocr_quality_check; print('quality checker OK')"` to verify import.
  </verify>
  <done>Three extractor/quality modules exist and are importable. pymupdf4llm extractor uses correct import order. pdfplumber extractor handles table bbox clamping. Quality checker implements all three heuristics with configurable thresholds.</done>
</task>

<task type="auto">
  <name>Task 2: Create per-document extraction service with tiered fallback</name>
  <files>src/cer_scraper/extractor/service.py</files>
  <action>
Create `src/cer_scraper/extractor/service.py` -- the per-document extraction orchestrator.

**Define shared types at module level:**

```python
class ExtractionMethod(Enum):
    PYMUPDF4LLM = "pymupdf4llm"
    PDFPLUMBER = "pdfplumber"
    TESSERACT = "tesseract"
    FAILED = "failed"

@dataclass
class ExtractionResult:
    success: bool
    markdown: str = ""
    method: ExtractionMethod = ExtractionMethod.FAILED
    page_count: int = 0
    char_count: int = 0
    error: str | None = None
```

**Main function: `extract_document(pdf_path: Path, settings: ExtractionSettings) -> ExtractionResult`**

Steps (per research Pattern 1):

1. **Encryption check**: Open with `pymupdf.open(str(pdf_path))`, check `doc.needs_pass`. If True, close and return ExtractionResult(success=False, error="encrypted"). Per user decision: skip entirely, mark as extraction_failed.

2. **Page count guard**: Get `len(doc)`, close doc. If page_count > `settings.max_pages_for_extraction` (300), return failure with error `f"too_many_pages ({page_count})"`.

3. **Tier 1 -- pymupdf4llm**: Call `try_pymupdf4llm(pdf_path, settings)`. Set result.page_count = page_count. If result.success AND `passes_quality_check(result, page_count, settings)`: return result. Log info about which method succeeded.

4. **Tier 2 -- pdfplumber**: Call `try_pdfplumber(pdf_path, settings)`. Set result.page_count = page_count. If result.success AND `passes_quality_check(result, page_count, settings)`: return result. Log that fallback was used.

5. **Tier 3 -- Tesseract OCR**: Only if page_count <= `settings.max_pages_for_ocr` (100). Call `try_tesseract_direct(pdf_path, settings)`. Set result.page_count = page_count. If result.success AND `passes_ocr_quality_check(result, page_count, settings)`: return result. Log that OCR fallback was used.

   If page_count > max_pages_for_ocr, skip Tesseract and log warning: "Skipping OCR for {page_count}-page document (max {settings.max_pages_for_ocr})".

6. **All failed**: Return ExtractionResult(success=False, method=FAILED, page_count=page_count, error="all_methods_failed").

**Tesseract direct function (in this same file): `try_tesseract_direct(pdf_path: Path, settings: ExtractionSettings) -> ExtractionResult`**

Implementation (research Pattern 4):
- Open PDF with `pymupdf.open(str(pdf_path))`
- For each page: render with `page.get_pixmap(dpi=settings.ocr_dpi)` (default 300)
- Convert pixmap to PIL Image: `pix.tobytes("png")` -> `Image.open(io.BytesIO(img_data))`
- OCR with `pytesseract.image_to_string(img, lang=settings.ocr_language)`
- If settings.tesseract_cmd != "tesseract", set `pytesseract.pytesseract.tesseract_cmd = settings.tesseract_cmd` before OCR
- Join pages with `\n\n---\n\n` separators
- Count meaningful chars, return ExtractionResult with method=TESSERACT
- Wrap in try/except

Log at INFO level which method was attempted and whether it succeeded or failed. Log at WARNING level when falling back to the next method.
  </action>
  <verify>
Run `uv run python -c "from cer_scraper.extractor.service import extract_document, ExtractionResult, ExtractionMethod; print('Service imports OK'); print(list(ExtractionMethod))"` to verify all exports.

If a test PDF is available in the data/filings directory, test extraction on it:
`uv run python -c "from pathlib import Path; from cer_scraper.extractor.service import extract_document; from cer_scraper.config.settings import ExtractionSettings; r = extract_document(Path('test.pdf'), ExtractionSettings()); print(r.success, r.method, r.char_count)"` (substitute actual PDF path).
  </verify>
  <done>extract_document function implements the full three-tier fallback pipeline. ExtractionResult and ExtractionMethod are defined and importable. Encrypted PDFs return "encrypted" error. Oversized PDFs return "too_many_pages" error. Quality checks trigger fallback between tiers. Tesseract is skipped for documents exceeding max_pages_for_ocr.</done>
</task>

</tasks>

<verification>
- All four files in `src/cer_scraper/extractor/` import without errors
- `ExtractionMethod` enum has four values: PYMUPDF4LLM, PDFPLUMBER, TESSERACT, FAILED
- `ExtractionResult` dataclass has all required fields
- `extract_document` function signature accepts `(Path, ExtractionSettings)` and returns `ExtractionResult`
- No circular imports between service.py, quality.py, pymupdf_extractor.py, pdfplumber_extractor.py
- Import order in pymupdf_extractor.py has `pymupdf.layout` before `pymupdf4llm`
</verification>

<success_criteria>
1. pymupdf4llm extractor converts PDFs to markdown with correct parameters and import order
2. pdfplumber extractor handles tables with bbox clamping and produces pipe-delimited markdown tables
3. Quality checker catches garbled output via three heuristics with configurable thresholds
4. OCR quality checker uses looser thresholds appropriate for Tesseract output
5. Service orchestrates tiered fallback: pymupdf4llm -> pdfplumber -> Tesseract -> failed
6. Encrypted PDFs and oversized PDFs handled as specified by user decisions
7. Tesseract skipped for documents exceeding max_pages_for_ocr guard
</success_criteria>

<output>
After completion, create `.planning/phases/04-pdf-text-extraction/04-02-SUMMARY.md`
</output>
