---
phase: 05-core-llm-analysis
plan: 03
type: execute
wave: 3
depends_on: ["05-01", "05-02"]
files_modified:
  - src/cer_scraper/analyzer/__init__.py
autonomous: true

must_haves:
  truths:
    - "analyze_filings processes all extracted-but-not-analyzed filings"
    - "Filing text is assembled by concatenating all successfully extracted documents with delimiter headers"
    - "Analysis JSON is saved both as analysis.json on disk and in Filing.analysis_json column"
    - "Filing status_analyzed is set to success or failed after analysis"
    - "One filing failure does not block other filings"
    - "Filings with no extracted documents are skipped, not failed"
    - "Timeout/error sets needs_chunking flag for Phase 7"
  artifacts:
    - path: "src/cer_scraper/analyzer/__init__.py"
      provides: "analyze_filings orchestrator function, AnalysisBatchResult dataclass, assemble_filing_text helper"
      exports: ["analyze_filings", "AnalysisBatchResult"]
  key_links:
    - from: "src/cer_scraper/analyzer/__init__.py"
      to: "src/cer_scraper/analyzer/service.py"
      via: "calls analyze_filing_text for each filing"
      pattern: "analyze_filing_text"
    - from: "src/cer_scraper/analyzer/__init__.py"
      to: "src/cer_scraper/db/state.py"
      via: "get_filings_for_analysis + mark_step_complete"
      pattern: "get_filings_for_analysis|mark_step_complete"
    - from: "src/cer_scraper/analyzer/__init__.py"
      to: "Filing.analysis_json"
      via: "stores json.dumps(result.analysis_json) in Filing.analysis_json"
      pattern: "analysis_json"
---

<objective>
Build the filing-level analysis orchestrator that assembles document text, invokes the analysis service, and persists results to both disk and database.

Purpose: This is the top-level entry point for the analysis pipeline step. It ties together the text assembly, CLI invocation, and result persistence -- mirroring the extractor orchestrator pattern but for LLM analysis.

Output: Complete analyzer/__init__.py with analyze_filings function, AnalysisBatchResult, and filing text assembly.
</objective>

<execution_context>
@C:\Users\amelv\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\amelv\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-core-llm-analysis/05-RESEARCH.md
@.planning/phases/05-core-llm-analysis/05-CONTEXT.md
@.planning/phases/05-core-llm-analysis/05-01-SUMMARY.md
@.planning/phases/05-core-llm-analysis/05-02-SUMMARY.md

# Pattern to follow closely
@src/cer_scraper/extractor/__init__.py   # Orchestrator pattern (extract_filings)

# Dependencies
@src/cer_scraper/analyzer/service.py     # analyze_filing_text
@src/cer_scraper/analyzer/types.py       # AnalysisResult
@src/cer_scraper/db/state.py             # get_filings_for_analysis, mark_step_complete
@src/cer_scraper/db/models.py            # Filing, Document
@src/cer_scraper/config/settings.py      # AnalysisSettings, PROJECT_ROOT
</context>

<tasks>

<task type="auto">
  <name>Task 1: Filing text assembly helper</name>
  <files>src/cer_scraper/analyzer/__init__.py</files>
  <action>
Replace the empty `__init__.py` with the analysis orchestrator module. Start with the text assembly helper:

1. Module docstring explaining this is the filing-level analysis orchestrator with per-filing error isolation. Follow the extractor/__init__.py docstring pattern exactly.

2. `__all__ = ["analyze_filings", "AnalysisBatchResult"]`

3. `assemble_filing_text(documents: list) -> tuple[str, int, int]`:
   - Iterate over the filing's documents (list of Document ORM objects)
   - For each document with `extraction_status == "success"` and non-empty `extracted_text`:
     - Build header: `"--- Document {idx}: {doc.filename or 'unknown.pdf'} ({doc.page_count or '?'} pages) ---"`
     - Append `f"{header}\n\n{doc.extracted_text}"` to parts list
     - Increment included count
   - For documents without successful extraction: increment missing count
   - Join parts with `"\n\n"`
   - Return `(combined_text, included_count, missing_count)`
   - This matches the locked decision: "Documents clearly delimited with headers in prompt"

4. `_save_analysis_json(filing_dir: Path, analysis_json: dict) -> None`:
   - Write `json.dumps(analysis_json, indent=2, ensure_ascii=False)` to `filing_dir / "analysis.json"`
   - Use `encoding="utf-8"` on open
   - Log the save at INFO level
   - This satisfies the locked decision: "Storage: both JSON file (analysis.json in filing's documents folder) AND database column"
  </action>
  <verify>
    Run: `python -c "from cer_scraper.analyzer import AnalysisBatchResult; print('import OK')"` -- should import without error (orchestrator is partially complete but importable).
  </verify>
  <done>
    assemble_filing_text concatenates extracted document texts with delimiter headers. _save_analysis_json writes analysis.json to filing directory.
  </done>
</task>

<task type="auto">
  <name>Task 2: Analysis orchestrator with batch processing and persistence</name>
  <files>src/cer_scraper/analyzer/__init__.py</files>
  <action>
Continue building the orchestrator in the same file (this task adds to what Task 1 created):

1. `AnalysisBatchResult` dataclass (mirrors ExtractionBatchResult / DownloadBatchResult):
   - `filings_attempted: int = 0`
   - `filings_succeeded: int = 0`
   - `filings_failed: int = 0`
   - `filings_skipped: int = 0` (no extracted text / insufficient text)
   - `total_cost_usd: float = 0.0`
   - `errors: list[str] = field(default_factory=list)`

2. `_analyze_single_filing(session, filing: Filing, settings: AnalysisSettings) -> tuple[bool, str | None, bool]`:
   - Assemble filing text with `assemble_filing_text(filing.documents)`
   - If `included_count == 0`: return `(True, None, True)` -- success + skipped (no documents to analyze, vacuous truth like extractor)
   - Call `analyze_filing_text(filing.filing_id, str(filing.date or ""), filing.applicant or "", filing.filing_type or "", combined_text, included_count, missing_count, settings)`
   - If result.success:
     - Determine filing directory from first successfully downloaded document's `local_path` parent
     - Call `_save_analysis_json(filing_dir, result.analysis_json)` inside try/except (disk write failure should not fail analysis)
     - Set `filing.analysis_json = json.dumps(result.analysis_json, ensure_ascii=False)`
     - Return `(True, None, False)`
   - If result.error == "insufficient_text":
     - Return `(True, None, True)` -- skip, not failure
   - If not result.success:
     - Log warning with error
     - Return `(False, result.error, False)`

3. `analyze_filings(session, analysis_settings: AnalysisSettings) -> AnalysisBatchResult`:
   - Follow the `extract_filings` pattern EXACTLY for structure:
     - Create AnalysisBatchResult
     - Query `get_filings_for_analysis(session, max_retries=3)`
     - Log count of filings found
     - For each filing:
       - Increment `filings_attempted`
       - Try `_analyze_single_filing`
       - On success: `mark_step_complete(session, filing.filing_id, "analyzed", "success")`, `session.commit()`, increment counters
       - On skip (third return value True): increment `filings_skipped`, still mark as "success" (vacuous truth)
       - On failure: `mark_step_complete(session, filing.filing_id, "analyzed", "failed", error=error_msg)`, `session.commit()`, increment counters, append to errors
       - On unexpected exception: `session.rollback()`, mark as failed, log exception (same error isolation pattern as extractor)
     - Log batch summary
     - Return batch result

Key patterns to follow from extractor/__init__.py:
- Each filing committed independently (`session.commit()` after each)
- Unexpected exception catches with rollback
- Outer try/except for fatal errors in orchestrator itself
- INFO logging for each filing start/end
- WARNING logging for failures
  </action>
  <verify>
    Run: `python -c "from cer_scraper.analyzer import analyze_filings, AnalysisBatchResult; b = AnalysisBatchResult(); print(f'attempted={b.filings_attempted}, cost={b.total_cost_usd}')"` -- should print zeros.

    Run: `python -c "from cer_scraper.analyzer import assemble_filing_text; print('assemble OK')"` -- function should be importable.

    Verify the module follows the extractor pattern: `python -c "import inspect; from cer_scraper.analyzer import analyze_filings; sig = inspect.signature(analyze_filings); print(list(sig.parameters.keys()))"` -- should print ['session', 'analysis_settings'].
  </verify>
  <done>
    analyze_filings processes all extracted-but-not-analyzed filings with per-filing error isolation. Filing text assembled from concatenated documents with headers. Analysis JSON saved to both disk (analysis.json) and database (Filing.analysis_json). Status updated to success/failed. Batch result tracks attempts, successes, failures, skips, and total cost.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from cer_scraper.analyzer import analyze_filings, AnalysisBatchResult; print('OK')"` -- clean import
2. `analyze_filings` signature matches `(session, analysis_settings)` pattern
3. `assemble_filing_text` concatenates documents with `--- Document N: filename (pages) ---` headers
4. `_save_analysis_json` writes to filing directory as analysis.json
5. Per-filing error isolation: each filing wrapped in try/except with rollback on unexpected errors
6. Each filing committed independently after analysis
7. Skipped filings (no documents, insufficient text) marked as success, not failure
</verification>

<success_criteria>
- analyze_filings is the top-level entry point matching extract_filings pattern
- Filing text assembled with document delimiter headers per locked decision
- Analysis JSON persisted to both disk AND database per locked decision
- Per-filing error isolation (one failure doesn't block others)
- Batch result provides attempt/success/fail/skip/cost metrics
- Timeout/error results set needs_chunking for Phase 7
</success_criteria>

<output>
After completion, create `.planning/phases/05-core-llm-analysis/05-03-SUMMARY.md`
</output>
